{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import time;\n",
    "import sagemaker as sg;\n",
    "import scipy;\n",
    "import csv;\n",
    "import xlearn as xl;\n",
    "import random;\n",
    "from tqdm import tqdm;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "import numpy as np;\n",
    "from sklearn.metrics import mean_squared_error;\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "dataLink :  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "groupLens: https://grouplens.org/datasets/movielens/\n",
    "readMe: http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "The data are contained in the files links.csv, movies.csv, ratings.csv and tags.csv. More details about the contents and use of all these files follows.\n",
    "\n",
    "This is a development dataset. As such, it may change over time and is not an appropriate dataset for shared research results. See available benchmark datasets if that is your intent.\n",
    "\n",
    "This and other GroupLens data sets are publicly available for download at http://grouplens.org/datasets/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genome_scores = pd.read_csv('ml-latest/genome-scores.csv')\n",
    "#genome_tags = pd.read_csv('ml-latest/genome-tags.csv')\n",
    "#links = pd.read_csv('ml-latest-small/links.csv')\n",
    "#movies = pd.read_csv('ml-1m/movies.dat')\n",
    "#ratings = pd.read_csv('ml-1m/ratings.dat')\n",
    "#users = pd.read_csv('ml-1m/users.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing data in libsvm & libffm format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Convert data to libsvm format\n",
    "\n",
    "\n",
    "### reading & convert ratings file\n",
    "\n",
    "def convert_ratings_to_fm(fin,fout,feature_index,rating_index,_model = \"fm\"):\n",
    "    '''\n",
    "    Input : ratings file with columns in the following order\n",
    "            1) user_id\n",
    "            2) movie_id\n",
    "            3) rating\n",
    "            4) timestamp - Ignoring this column for now\n",
    "            \n",
    "    Arguments : fin : input ratings file\n",
    "                fout : output file name - column indices to be included\n",
    "                column index containing the rating\n",
    "                _model : ffm/fm\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "            ratings matrix transformed to libsvm\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    rat_file = open(fin,'r')  #input file\n",
    "    text_file = open(fout,'w') #output file\n",
    "    \n",
    "    \n",
    "    if _model==\"ffm\":\n",
    "        add_field = 1\n",
    "    else:\n",
    "        add_field = 0\n",
    "    \n",
    "    \n",
    "    #Initialize ::\n",
    "    val0 = rat_file.readline();\n",
    "    split_row0 = val0.split('::')\n",
    "    datastring = \"\"  #stores the final string\n",
    "    indx_cntr = 0\n",
    "    d_field = {}\n",
    "\n",
    "    ###User\n",
    "    d_field[feature_index[0]] = {split_row0[0] : indx_cntr}\n",
    "    indx_cntr = indx_cntr + 1\n",
    "    ###movie\n",
    "    d_field[feature_index[1]] = {split_row0[1] : indx_cntr}\n",
    "    indx_cntr = indx_cntr + 1\n",
    "    ###first string\n",
    "    ###rating\n",
    "    datastring += str(int(split_row0[rating_index]))\n",
    "    ###user   \n",
    "    datastring += \",\" + (\"0\" + \":\") * add_field + str(d_field[0][split_row0[0]]) + \":\" + \"1\"\n",
    "    ###movie\n",
    "    datastring += \",\" + (\"1\" + \":\") * add_field + str(d_field[1][split_row0[1]]) + \":\" + \"1\"\n",
    "    \n",
    "    datastring += \"\\n\"\n",
    "    text_file.write(datastring) \n",
    "    \n",
    "    #iterate over all the lines\n",
    "    for val in rat_file.readlines():\n",
    "\n",
    "        #split each row\n",
    "        split_row = val.split('::')\n",
    "        #rating\n",
    "        datastring = str(int(split_row[rating_index]))\n",
    "        for col in feature_index: #ignoring timestamp, rating\n",
    "           \n",
    "            #if a new user/movie found, add it to dictionary\n",
    "            if d_field[col].get(split_row[col],None) == None:\n",
    "                d_field[col][split_row[int(col)]] = indx_cntr\n",
    "                indx_cntr += 1\n",
    "\n",
    "            datastring += \",\" + (str(col) + \":\") * add_field + str(d_field[col][split_row[col]]) + \":\" + \"1\"\n",
    "        datastring += \"\\n\"\n",
    "        text_file.write(datastring)        \n",
    "         \n",
    "    text_file.close()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running a basic model to check if the code is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_ratings_to_fm(\"ml-1m/ratings.dat\",\"ratings_v1\",[0,1],2,_model = \"fm\")\n",
    "fm_model = xl.create_fm()\n",
    "fm_model.setTrain(\"./fout\")\n",
    "#fm_model.setValidate(\"./small_test.txt\")\n",
    "param = {'task':'reg', 'lr':0.2, 'lambda':0.002}\n",
    "\n",
    "fm_model.fit(param, \"./model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_ratings_to_fm(\"ml-1m/ratings.dat\",\"ratings_v1\",[0,1],2,_model = \"ffm\")\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"./testffm.txt\")\n",
    "#fm_model.setValidate(\"./small_test.txt\")\n",
    "param = {'task':'reg', 'lr':0.2, 'lambda':0.002}\n",
    "\n",
    "ffm_model.fit(param, \"./model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_ratings_to_fm(\"ml-1m/ratings.dat\",\"ratings_v1\",[0,1],2,_model = \"fm\")\n",
    "convert_ratings_to_fm(\"ml-1m/ratings.dat\",\"ratings_v1\",[0,1],2,_model = \"ffm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a train - test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(fname,test_percent,delimiter,seed = 242):\n",
    "    \n",
    "    '''\n",
    "    Input : File for ratings\n",
    "    \n",
    "    Output : test/train files with \"train_\" + fname & \"test_\" + fname, returns True if split is correct, \n",
    "             False otherwise\n",
    "    \n",
    "    Argument : fname : File which has the ratings\n",
    "               test_percent : percentage of ratings in test\n",
    "               seed : seed\n",
    "               delimiter : delimeter of the ratings file\n",
    "                  \n",
    "    '''\n",
    "    \n",
    "    file = open(fname)\n",
    "    x = file.readlines()\n",
    "    \n",
    "    test_indices = random.sample(k = int(len(x) * test_percent), population = range(len(x)))\n",
    "    train_indices = set(range(len(x))) - set(test_indices)\n",
    "    \n",
    "    tmp = fname.split(\".\")[0]\n",
    "    \n",
    "    f_train = open(tmp + \"train.dat\",\"w\")\n",
    "    [f_train.write(x[i]) for i in train_indices]\n",
    "    f_train.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    f_test = open(tmp + \"test.dat\",\"w\")\n",
    "    [f_test.write(x[i]) for i in test_indices]\n",
    "    f_test.close()\n",
    "    \n",
    "       \n",
    "    x = np.genfromtxt(tmp + \"train.dat\",delimiter = delimiter)\n",
    "    y = np.genfromtxt(tmp + \"test.dat\",delimiter = delimiter)\n",
    "    \n",
    "    \n",
    "    ##checks if train user items are superset of y\n",
    "    return set(np.unique(x[:,0])).issuperset(np.unique(y[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create test control\n",
    "train_test_split(\"ml-1m/ratings.dat\",.20,\"::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_rmse\n",
    "mean_squared_error(y_true, ypred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A) : Attempting a simple Factorization machine on 1 Million dataset - with just User X Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "param = {\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "fm_A_model.setTest(\"ml-1m/ratingstest.dat\")\n",
    "#fm_A_model.setSigmoid()\n",
    "fm_A_model.predict(\"Models/model_fm_A.out\", \"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "     'task':'reg', # ‘binary’ for classification, ‘reg’ for Regression\n",
    "     'k':2,           # Size of latent factor\n",
    "     'lr':0.1,        # Learning rate for GD\n",
    "     'lambda':0.0002, # L2 Regularization Parameter\n",
    "     'Metric':'auc',  # Metric for monitoring validation set performance\n",
    "     'epoch':25  ,     # Maximum number of Epochs\n",
    "     'opt':'sgd'      #optimization method\n",
    "     \n",
    "     \n",
    "     # hyperameters\n",
    "     ,'alpha':0.002, 'beta':0.8, 'lambda_1':0.001, 'lambda_2': 1.0\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_A_model = xl.create_fm()\n",
    "fm_A_model.setTrain(\"ml-1m/ratingstrain.dat\")\n",
    "fm_A_model.cv(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print \"Training with params : \"\n",
    "    print params\n",
    "    \n",
    "    fm_A_model = xl.create_fm()\n",
    "    fm_A_model.setTrain(\"ml-1m/ratingstrain.dat\")\n",
    "    fm_A_model.cv(param)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print \"\\tScore {0}\\n\\n\".format(score)\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(trials):\n",
    "    space = {\n",
    "         'task':'reg', # ‘binary’ for classification, ‘reg’ for Regression\n",
    "         'k':2,           # Size of latent factor\n",
    "         'lr':0.1,        # Learning rate for GD\n",
    "         'lambda':0.0002, # L2 Regularization Parameter\n",
    "         'Metric':'auc',  # Metric for monitoring validation set performance\n",
    "         'epoch':25  ,     # Maximum number of Epochs\n",
    "         'opt':'sgd'      #optimization method\n",
    "         \n",
    "         \n",
    "         # hyperameters\n",
    "         ,'alpha':0.002, 'beta':0.8, 'lambda_1':0.001, 'lambda_2': 1.0\n",
    "          }\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "\n",
    "    print best\n",
    "\n",
    "\n",
    "\n",
    "X, y = trains,target\n",
    "print \"Splitting data into train and valid ...\\n\\n\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "#Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "\n",
    "optimize(trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Benchmark it with Matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] n\n",
      "Ok then, I'm out!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/som/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "#data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"./small_train.txt\")\n",
    "ffm_model.setValidate(\"./small_test.txt\")\n",
    "ffm_model.setPreModel(\"./pre_model\")\n",
    "param = {'task':'binary', 'lr':0.2, 'lambda':0.002}\n",
    "\n",
    "ffm_model.fit(param, \"./model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
